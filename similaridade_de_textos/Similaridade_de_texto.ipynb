{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculando Containment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Neste notebook, iremos implementar uma funação containment. Tal função irá comparar dois textose analisar a similaridade dos mesmos com relação aos seus n-gramas de interseção.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contar N-gram counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primeiramente temos que contar as ocorrências de n-gramas dos nossos textos. Usaremos o CountVectorizer para converter o conjunto de dados de texto em uma matriz de contagem.\n",
    "\n",
    "No código abaixo, podemos variar o valor de n e utilizar o CountVectorizer para contar as ocorrências de n gramas. Podemos notar que na célula abaixo estamos criando um vocabulário através da utilização do CountVectorizer e, posteriormente, iremos analisar a matriz de contagem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sklearn\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unigrama"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "A execução do exemplo imprime o vocabulário. Podemos ver que existem 8 palavras no vocabulário e, portanto, vetores codificados também possuem um comprimento de 8."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'suponha': 6, 'que': 4, 'essa': 2, 'seja': 5, 'texto': 7, 'principal': 3, 'desejo': 1, 'comparar': 0}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "a_text = \"Suponha que essa seja o texto principal\"\n",
    "s_text = \"Suponha que essa seja o texto que desejo comparar\"\n",
    "\n",
    "# Número de n_gramas\n",
    "n = 1\n",
    "\n",
    "# Instancia o contador de n-gramas\n",
    "counts = CountVectorizer(analyzer='word', ngram_range=(n,n))\n",
    "\n",
    "# Cria um dicionário de n-gramas \n",
    "vocab2int = counts.fit([a_text, s_text]).vocabulary_\n",
    "\n",
    "# Printa dicionário de palavraś:index\n",
    "print(vocab2int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bigrama"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O mesmo vale para o caso dec bigramas. Temos 8 bigramas no vocabulário e ,portanto, os vetore codificados com comprimento 8."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'suponha que': 5, 'que essa': 3, 'essa seja': 1, 'seja texto': 4, 'texto principal': 6, 'texto que': 7, 'que desejo': 2, 'desejo comparar': 0}\n"
     ]
    }
   ],
   "source": [
    "# Número de n_gramas\n",
    "n = 2\n",
    "    \n",
    "# Instancia o contador de n-gramas\n",
    "counts = CountVectorizer(analyzer='word', ngram_range=(n,n))\n",
    "\n",
    "# Cria um dicionário de n-gramas \n",
    "vocab2int = counts.fit([a_text, s_text]).vocabulary_\n",
    "\n",
    "# Printa dicionário de palavraś:index\n",
    "print(vocab2int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trigrama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'suponha que essa': 5, 'que essa seja': 2, 'essa seja texto': 0, 'seja texto principal': 3, 'seja texto que': 4, 'texto que desejo': 6, 'que desejo comparar': 1}\n"
     ]
    }
   ],
   "source": [
    "# Número de n_gramas\n",
    "n = 3\n",
    "\n",
    "# Instancia o contador de n-gramas\n",
    "counts = CountVectorizer(analyzer='word', ngram_range=(n,n))\n",
    "\n",
    "# Cria um dicionário de n-gramas \n",
    "vocab2int = counts.fit([a_text, s_text]).vocabulary_\n",
    "\n",
    "# Printa dicionário de palavraś:index\n",
    "print(vocab2int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### As palavras do vocabulário"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note que o artigo \"o\" das frases a_text e s_text não aparece no vocabulário. Note ainda que todas as frases encontram-se em minúsculo. Isso ocorre devido ao fato de que quando passamos o parâmetro **analyser = 'word'**, estamos considerando em nossa análise palavras com dois ou mais caracteres e consequentemente ignrando as palavras com apenas um caracter. Excluir esses caracteres é um comportamento padrão e desejado em muitas análises de texto devido a sua irrelevancia, em grande parte das análises textuais.\n",
    "\n",
    "Caso você precise desconsiderar o padrão default do CountVectorizer e adicionar palavras com caracteres únicos em sua análise, você pode adicionar o argumento **token_pattern = r\"(?u)\\b\\w+\\b\"**. Essa expressão regular (REGEX) define palavra como tendo uma ou mais caracteres."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Array de n-gramas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos usar o CountVectorizer para criar um array com as contagens de n-gramas. Além disso, vamos criar duas frase que desejamos analizar, e transformar cada texto em um vetor numérico representando a ocorrência de cada palavra."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notar que cada linha representa um texto e cada coluna ou index reprsenta os termos do vocabulário. Iremos ver isso claramente no mapeamento abaixo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* texto_1 = \"Suponha que essa seja o texto principal\"\n",
    "* texto_2 = \"Suponha que essa seja o texto que desejo comparar\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vetor de n-gramas:\n",
      "\n",
      " [[0 0 1 1 1 1 1 1]\n",
      " [1 1 1 0 2 1 1 1]]\n",
      "\n",
      "Dicionário de n-gramas (unigrama):\n",
      "\n",
      " {'suponha': 6, 'que': 4, 'essa': 2, 'seja': 5, 'texto': 7, 'principal': 3, 'desejo': 1, 'comparar': 0}\n"
     ]
    }
   ],
   "source": [
    "# N-gramas \n",
    "n = 1\n",
    "\n",
    "# Instancia o contador de n-gramas\n",
    "counts = CountVectorizer(analyzer='word', ngram_range=(n,n))\n",
    "\n",
    "# cria uma matriz de contagem de n-grama para os dois textos\n",
    "n_grams = counts.fit_transform([texto_1,texto_2])\n",
    "\n",
    "# Cria um dicionário de n-gramas \n",
    "vocab2int = counts.fit([a_text, s_text]).vocabulary_\n",
    "\n",
    "n_grams_array = n_grams.toarray()\n",
    "print('Vetor de n-gramas:\\n\\n', n_grams_array)\n",
    "print()\n",
    "print('Dicionário de n-gramas (unigrama):\\n\\n', vocab2int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "texto_1 = \"Suponha que essa seja o texto principal\"\n",
    "texto_2 = \"Suponha que essa seja o texto que desejo comparar\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Acima temos os vetores que codificam cada texto. Na linha superior temos os n-gramas do `text_1` e na linha inferior temos a codificação do `text_2`. Podemos analisar se os textos possuem n_gramas em comum através de suas colunas. Por exemplo, ambos possuem a palavra texo (índice 7 - ultima coluna coluna). O mesmo vale para os unigramas [essa], [seja] e [suponha]. Notar que o unigrama \"que\" ocorre duas vezes no segundo texto. \n",
    "\n",
    "\n",
    "```\n",
    "[[0 0 1 1 1 1 1 1]    =   ________  ______ [essa] principal [que] [seja] [suponha] [texto]\n",
    " [1 1 1 0 2 1 1 1]]   =   comparar  desejo [essa] _________ [que] [seja] [suponha] [texto]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Valores de containment "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O Containment nada mais é do que uma medida de similaridade entre textos. É basicamente uma normalização da interseção da contagem de n-gramas entre os textos.\n",
    "\n",
    "\n",
    "Primeiro, precisamos extrair as palavras dos dois documentos de texto para formar um corpus.Em seguida, contamos a interseção de n-gramas (agrupamentos seqüenciais de palavras de n palavras) entre os textos 1 e o texto 2. Para o caso de unigramas, podemos considecrar como uma contagem  dos número de palavras que ambos os textos têm em comum.\n",
    "\n",
    "Em seguida, dividimos o valor pelo total de n-gramas do texto 2 (o qual quer ser comparado com o texto fonte) para normalizar o valor.\n",
    "\n",
    "\n",
    "Calculo de Containment:\n",
    "\n",
    "1. Calcular a interseção n-grama entre o texto e o texto fonte.\n",
    "2. Adicionar o número de termos comuns.\n",
    "3. Normalizar o valor na etapa 2 pelo número de n gramas no texto 2.\n",
    "\n",
    "\n",
    "Abaixo podemos ver a equação dec Containment: \n",
    "$$ \\frac{\\sum{count(\\text{ngram}_{2}) \\cap count(\\text{ngram}_{1})}}{\\sum{count(\\text{ngram}_{2})}} $$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos criar uma função que recebe um array de-gramas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def containment(n_gram_array):\n",
    "    ''' Calcula o containment entre dois textos. Normaliza a interseção dos contadores de n-gramas\n",
    "    entre os textos.\n",
    "    ARG:\n",
    "    n_gra_array(array): Um array com as contagens de n-gramas dos dois textos a serem comparados\n",
    "    \n",
    "    RETURNS:\n",
    "    O valor de containment normalizado '''\n",
    "    \n",
    "    \n",
    "     # Cria uma lista que contém o valor mínimo encontrado nas colunas\n",
    "     # 0 se não houver correspondências e 1+ para as palavras correspondentes\n",
    "    \n",
    "    intersection_list = np.amin(n_gram_array, axis = 0)\n",
    "    \n",
    "    # Soma numero de interseção\n",
    "    intersection_count = np.sum(intersection_list)\n",
    "    \n",
    "    # Conta número dec n-gramas no texto 1\n",
    "    answer_idx = 0\n",
    "    answer_count = np.sum(n_gram_array[answer_idx])\n",
    "    \n",
    "    \n",
    "    # Normaliza e calcula valor final \n",
    "    containment_val = intersection_count / answer_count\n",
    "    \n",
    "    return containment_val  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Para o n_gram calculado anteriormente e n = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Containment:  0.8333333333333334\n"
     ]
    }
   ],
   "source": [
    "\n",
    "containment_val = containment(n_grams.toarray())\n",
    "\n",
    "print('Containment: ', containment_val)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### para n = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Containment for n=2 :  0.8\n"
     ]
    }
   ],
   "source": [
    "# para n = n\n",
    "counts_2grams = CountVectorizer(analyzer='word', ngram_range=(2,2))\n",
    "bigram_counts = counts_2grams.fit_transform([a_text, s_text])\n",
    "\n",
    "# Calcula containment\n",
    "containment_val = containment(bigram_counts.toarray())\n",
    "\n",
    "print('Containment for n=2 : ', containment_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Teste a função com diferentes textos , n-gramas e tente imaginar aplicações desse conceito. Por exemplo, podemos usar essa técnica como uma métrica de análise de similaridade para detectar plagiarismo.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
